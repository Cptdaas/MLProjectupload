{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "from pathlib import Path\n",
    "\n",
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain import OpenAI\n",
    "from langchain.llms.openai import OpenAIChat\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma, Pinecone\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory.chat_message_histories import StreamlitChatMessageHistory\n",
    "\n",
    "import streamlit as st\n",
    "\n",
    "\n",
    "TMP_DIR = Path(__file__).resolve().parent.joinpath('data', 'tmp')\n",
    "LOCAL_VECTOR_STORE_DIR = Path(__file__).resolve().parent.joinpath('data', 'vector_store')\n",
    "\n",
    "st.set_page_config(page_title=\"RAG\")\n",
    "st.title(\"Retrieval Augmented Generation Engine\")\n",
    "\n",
    "if 'messages' not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "def load_documents():\n",
    "    loader = DirectoryLoader(TMP_DIR.as_posix(), glob='**/*.pdf')\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "def split_documents(documents):\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    return texts\n",
    "\n",
    "def embeddings_on_local_vectordb(texts):\n",
    "    vectordb = Chroma.from_documents(texts, embedding=OpenAIEmbeddings(),\n",
    "                                     persist_directory=LOCAL_VECTOR_STORE_DIR.as_posix())\n",
    "    vectordb.persist()\n",
    "    retriever = vectordb.as_retriever(search_kwargs={'k': 7})\n",
    "    return retriever\n",
    "\n",
    "def query_llm(retriever, query):\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=OpenAIChat(openai_api_key=st.session_state.openai_api_key),\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True,\n",
    "    )\n",
    "    result = qa_chain({'question': query, 'chat_history': st.session_state.messages})\n",
    "    result = result['answer']\n",
    "    st.session_state.messages.append((query, result))\n",
    "    return result\n",
    "\n",
    "# # Streamlit UI components\n",
    "# st.sidebar.title(\"Settings\")\n",
    "# st.sidebar.text_input(\"OpenAI API Key\", type=\"password\", key=\"openai_api_key\")\n",
    "# st.sidebar.text_input(\"Pinecone API Key\", type=\"password\", key=\"pinecone_api_key\")\n",
    "# st.sidebar.text_input(\"Pinecone Environment\", key=\"pinecone_env\")\n",
    "# st.sidebar.text_input(\"Pinecone Index Name\", key=\"pinecone_index\")\n",
    "\n",
    "st.header(\"Document Loading and Embedding\")\n",
    "if st.button(\"Load and Process Documents\"):\n",
    "    documents = load_documents()\n",
    "    texts = split_documents(documents)\n",
    "    retriever = embeddings_on_local_vectordb(texts)\n",
    "    st.session_state.retriever = retriever\n",
    "    st.success(\"Documents loaded and processed!\")\n",
    "\n",
    "st.header(\"Query the LLM\")\n",
    "query = st.text_input(\"Enter your question:\")\n",
    "if st.button(\"Submit Query\"):\n",
    "    if 'retriever' in st.session_state:\n",
    "        answer = query_llm(st.session_state.retriever, query)\n",
    "        st.write(f\"Answer: {answer}\")\n",
    "    else:\n",
    "        st.error(\"Please load and process documents first.\")\n",
    "\n",
    "st.header(\"Chat History\")\n",
    "for i, (question, answer) in enumerate(st.session_state.messages):\n",
    "    st.write(f\"Q{i+1}: {question}\")\n",
    "    st.write(f\"A{i+1}: {answer}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
